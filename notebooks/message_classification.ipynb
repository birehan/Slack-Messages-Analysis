{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv('../data/slack_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['msg_id', 'text', 'cleaned_text', 'user_id', 'mentions', 'reactions',\n",
       "       'replies', 'ts', 'channel_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>reactions</th>\n",
       "      <th>replies</th>\n",
       "      <th>ts</th>\n",
       "      <th>channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16f68d4e-0ceb-448a-b660-d5ef2eb05305</td>\n",
       "      <td>*HOTSEAT ANNOUNCEMENT*</td>\n",
       "      <td>hotseat announc</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.662621e+09</td>\n",
       "      <td>C03T0APHX63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7c641275-2e52-4074-9894-744f049d5377</td>\n",
       "      <td>*&lt;!here&gt;* Good morning Community! We are very ...</td>\n",
       "      <td>good morn commun happi excit announc today hot...</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>['U03U1GHT39V']</td>\n",
       "      <td>[{'name': 'fire', 'users': ['U03U9FWPNCE'], 'c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.662621e+09</td>\n",
       "      <td>C03T0APHX63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245ecc4d-2c1b-4bee-b280-a1fd5ab7fee3</td>\n",
       "      <td>*&lt;!here&gt; Community Building Session REMINDER!*...</td>\n",
       "      <td>commun build session remindertimerclock plea n...</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'name': 'heart_eyes', 'users': ['U03UG4Q7V42...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.662638e+09</td>\n",
       "      <td>C03T0APHX63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe80aff2-20f2-42ad-94a8-8b48ac63083f</td>\n",
       "      <td>Sweet music on Google meet now\\n:point_right: ...</td>\n",
       "      <td>sweet music googl meet pointright meetgoogleco...</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.662638e+09</td>\n",
       "      <td>C03T0APHX63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2be29318-9c50-4b56-ae0b-ae8bcd4c92a3</td>\n",
       "      <td>Hellooo Helllo again my people the lovely  com...</td>\n",
       "      <td>hellooo helllo peopl love commun guy ……it cb t...</td>\n",
       "      <td>U03V1AM5TFA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.662638e+09</td>\n",
       "      <td>C03T0APHX63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 msg_id  \\\n",
       "0  16f68d4e-0ceb-448a-b660-d5ef2eb05305   \n",
       "1  7c641275-2e52-4074-9894-744f049d5377   \n",
       "2  245ecc4d-2c1b-4bee-b280-a1fd5ab7fee3   \n",
       "3  fe80aff2-20f2-42ad-94a8-8b48ac63083f   \n",
       "4  2be29318-9c50-4b56-ae0b-ae8bcd4c92a3   \n",
       "\n",
       "                                                text  \\\n",
       "0                             *HOTSEAT ANNOUNCEMENT*   \n",
       "1  *<!here>* Good morning Community! We are very ...   \n",
       "2  *<!here> Community Building Session REMINDER!*...   \n",
       "3  Sweet music on Google meet now\\n:point_right: ...   \n",
       "4  Hellooo Helllo again my people the lovely  com...   \n",
       "\n",
       "                                        cleaned_text      user_id  \\\n",
       "0                                    hotseat announc  U03V1AM5TFA   \n",
       "1  good morn commun happi excit announc today hot...  U03V1AM5TFA   \n",
       "2  commun build session remindertimerclock plea n...  U03V1AM5TFA   \n",
       "3  sweet music googl meet pointright meetgoogleco...  U03V1AM5TFA   \n",
       "4  hellooo helllo peopl love commun guy ……it cb t...  U03V1AM5TFA   \n",
       "\n",
       "          mentions                                          reactions replies  \\\n",
       "0               []                                                 []      []   \n",
       "1  ['U03U1GHT39V']  [{'name': 'fire', 'users': ['U03U9FWPNCE'], 'c...      []   \n",
       "2               []  [{'name': 'heart_eyes', 'users': ['U03UG4Q7V42...      []   \n",
       "3               []                                                 []      []   \n",
       "4               []                                                 []      []   \n",
       "\n",
       "             ts   channel_id  \n",
       "0  1.662621e+09  C03T0APHX63  \n",
       "1  1.662621e+09  C03T0APHX63  \n",
       "2  1.662638e+09  C03T0APHX63  \n",
       "3  1.662638e+09  C03T0APHX63  \n",
       "4  1.662638e+09  C03T0APHX63  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.894400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.664502e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.081142e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.661014e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.662553e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.664540e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.666002e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.674215e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ts\n",
       "count  1.894400e+04\n",
       "mean   1.664502e+09\n",
       "std    2.081142e+06\n",
       "min    1.661014e+09\n",
       "25%    1.662553e+09\n",
       "50%    1.664540e+09\n",
       "75%    1.666002e+09\n",
       "max    1.674215e+09"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  \\\n",
      "18934                                        ETL and ELT   \n",
      "18935                                     Finally :grin:   \n",
      "18936                The beginning of the End:joy: :joy:   \n",
      "18937                                      12 of 12:100:   \n",
      "18938  :timer_clock:*REMINDER*:timer_clock: *REMINDER...   \n",
      "18939  <@U03TEPYRM2P> so, do we unsubmit  the assignm...   \n",
      "18940  Please use the submission link for week 12 to ...   \n",
      "18941                                     oh, ok thanks!   \n",
      "18942  How can I get the trainees that opted-in a giv...   \n",
      "18943  <https://developer.algorand.org/solutions/mint...   \n",
      "\n",
      "              predicted_label  \n",
      "18934  Question Non-Technical  \n",
      "18935  Question Non-Technical  \n",
      "18936  Question Non-Technical  \n",
      "18937  Question Non-Technical  \n",
      "18938  Question Non-Technical  \n",
      "18939  Question Non-Technical  \n",
      "18940  Question Non-Technical  \n",
      "18941  Question Non-Technical  \n",
      "18942  Question Non-Technical  \n",
      "18943  Question Non-Technical  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228101/1129900514.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df['predicted_label'] = [labels_mapping[label] for label in torch.argmax(outputs.logits, dim=1).numpy()]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Load pre-trained ALBERT model and tokenizer\n",
    "model_name = \"albert-base-v2\"\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "model = AlbertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "subset_df = data.tail(10)\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and has the column 'cleaned_text'\n",
    "\n",
    "# Define prompts for classification\n",
    "prompts = {\n",
    "    'Question Technical': \"Identify if the following is a technical question related to a specific topic: \",\n",
    "    'Question Non-Technical': \"Identify if the following is a non-technical question: \",\n",
    "    'Comment Technical': \"Determine if the following is a technical comment discussing a specific topic: \",\n",
    "    'Comment Non-Technical': \"Determine if the following is a non-technical comment: \",\n",
    "    'Answer': \"Classify the following as an answer to a question: \",\n",
    "    'Other': \"Categorize the following as miscellaneous or not falling into the specified categories: \"\n",
    "}\n",
    "\n",
    "# Tokenize and encode the cleaned_text with the prompts\n",
    "tokenized_texts = [tokenizer.encode(prompts.get(label, \"\") + text, add_special_tokens=True) for label, text in zip(subset_df['text'], subset_df['text'])]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_len = max(map(len, tokenized_texts))\n",
    "padded_texts = [text + [0] * (max_len - len(text)) for text in tokenized_texts]\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_ids = torch.tensor(padded_texts)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    probs = torch.softmax(outputs.logits, dim=1).numpy()\n",
    "\n",
    "# Define label mappings\n",
    "labels_mapping = {\n",
    "    0: 'Question Technical',\n",
    "    1: 'Question Non-Technical',\n",
    "    2: 'Comment Technical',\n",
    "    3: 'Comment Non-Technical',\n",
    "    4: 'Answer',\n",
    "    5: 'Other'\n",
    "}\n",
    "\n",
    "# Assign labels based on probabilities\n",
    "subset_df['predicted_label'] = [labels_mapping[label] for label in torch.argmax(outputs.logits, dim=1).numpy()]\n",
    "\n",
    "print(subset_df[['text', 'predicted_label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text         predicted_label\n",
      "0                             *HOTSEAT ANNOUNCEMENT*  Question Non-Technical\n",
      "1  *<!here>* Good morning Community! We are very ...  Question Non-Technical\n",
      "2  *<!here> Community Building Session REMINDER!*...  Question Non-Technical\n",
      "3  Sweet music on Google meet now\\n:point_right: ...  Question Non-Technical\n",
      "4  Hellooo Helllo again my people the lovely  com...  Question Non-Technical\n",
      "5                                                yes      Question Technical\n",
      "6                                                yes      Question Technical\n",
      "7                                                Yes      Question Technical\n",
      "8                                                Yes      Question Technical\n",
      "9                                                Yep      Question Technical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228101/3944072759.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df['predicted_label'] = [labels_mapping[label] for label in torch.argmax(outputs.logits, dim=1).numpy()]\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Load pre-trained RoBERTa model and tokenizer\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and has the column 'cleaned_text'\n",
    "\n",
    "# Select only the first 10 rows from the DataFrame\n",
    "subset_df = data.head(10)\n",
    "\n",
    "# Define a prompt for classification (customize it based on your task)\n",
    "prompt_template = \"Classify the following text: {}\"\n",
    "\n",
    "# Tokenize and encode the cleaned_text with the prompt\n",
    "tokenized_texts = [tokenizer.encode(prompt_template.format(text), add_special_tokens=True) for text in subset_df['text']]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_len = max(map(len, tokenized_texts))\n",
    "padded_texts = [text + [0] * (max_len - len(text)) for text in tokenized_texts]\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_ids = torch.tensor(padded_texts)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    probs = torch.softmax(outputs.logits, dim=1).numpy()\n",
    "\n",
    "# Define label mappings\n",
    "labels_mapping = {\n",
    "    2: 'Comment Technical',\n",
    "    4: 'Answer',\n",
    "    0: 'Question Technical',\n",
    "    1: 'Question Non-Technical',\n",
    "    3: 'Comment Non-Technical',\n",
    "    5: 'Other'\n",
    "}\n",
    "\n",
    "# Assign labels based on probabilities\n",
    "subset_df['predicted_label'] = [labels_mapping[label] for label in torch.argmax(outputs.logits, dim=1).numpy()]\n",
    "\n",
    "# Display the result\n",
    "print(subset_df[['text', 'predicted_label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text     predicted_label\n",
      "18934                                        ETL and ELT  Question Technical\n",
      "18935                                     Finally :grin:  Question Technical\n",
      "18936                The beginning of the End:joy: :joy:  Question Technical\n",
      "18937                                      12 of 12:100:  Question Technical\n",
      "18938  :timer_clock:*REMINDER*:timer_clock: *REMINDER...  Question Technical\n",
      "18939  <@U03TEPYRM2P> so, do we unsubmit  the assignm...  Question Technical\n",
      "18940  Please use the submission link for week 12 to ...  Question Technical\n",
      "18941                                     oh, ok thanks!  Question Technical\n",
      "18942  How can I get the trainees that opted-in a giv...  Question Technical\n",
      "18943  <https://developer.algorand.org/solutions/mint...  Question Technical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228101/3005440968.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df['predicted_label'] = [labels_mapping[label] for label in torch.argmax(outputs.logits, dim=1).numpy()]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Load pre-trained ALBERT model and tokenizer\n",
    "model_name = \"albert-base-v2\"\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "model = AlbertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "subset_df = data.tail(10)\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and has the column 'cleaned_text'\n",
    "\n",
    "# Define a new prompt for classification\n",
    "prompt_template = \"Evaluate the text: {} Class labels: Question Technical (0), Question Non-Technical (1), Comment Technical (2), Comment Non-Technical (3), Answer (4), Other (5)\"\n",
    "\n",
    "# Tokenize and encode the cleaned_text with the new prompt\n",
    "tokenized_texts = [tokenizer.encode(prompt_template.format(text), add_special_tokens=True) for text in subset_df['text']]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_len = max(map(len, tokenized_texts))\n",
    "padded_texts = [text + [0] * (max_len - len(text)) for text in tokenized_texts]\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_ids = torch.tensor(padded_texts)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    probs = torch.softmax(outputs.logits, dim=1).numpy()\n",
    "\n",
    "# Define label mappings\n",
    "labels_mapping = {\n",
    "    0: 'Question Technical',\n",
    "    1: 'Question Non-Technical',\n",
    "    2: 'Comment Technical',\n",
    "    3: 'Comment Non-Technical',\n",
    "    4: 'Answer',\n",
    "    5: 'Other'\n",
    "}\n",
    "\n",
    "# Assign labels based on probabilities\n",
    "subset_df['predicted_label'] = [labels_mapping[label] for label in torch.argmax(outputs.logits, dim=1).numpy()]\n",
    "\n",
    "print(subset_df[['text', 'predicted_label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            cleaned_text predicted_label\n",
      "18934                                            etl elt        Question\n",
      "18935                                         final grin        Question\n",
      "18936                                   begin endjoy joy        Question\n",
      "18937                                                NaN        Question\n",
      "18938  timerclockremindertimerclock remind timerclock...          Answer\n",
      "18939  unsubmit assign submit suppos submit new assig...        Question\n",
      "18940                  plea use submiss link week submit        Question\n",
      "18941                                        oh ok thank        Question\n",
      "18942  get traine optedin given asset print statu ass...          Answer\n",
      "18943                                                NaN        Question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228101/2729351970.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df['predicted_label'] = [labels_mapping[label] for label in torch.argmax(outputs.logits, dim=1).numpy()]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Load pre-trained XLNet model and tokenizer\n",
    "model_name = \"xlnet-base-cased\"\n",
    "tokenizer = XLNetTokenizer.from_pretrained(model_name)\n",
    "model = XLNetForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and has the column 'cleaned_text'\n",
    "subset_df = data.tail(10)\n",
    "\n",
    "# Define a prompt for classification (customize it based on your task)\n",
    "prompt_template = \"Classify the following text: {} Class labels: Question (0), Answer (1), Comment (2), Other (3)\"\n",
    "\n",
    "# Tokenize and encode the cleaned_text with the prompt\n",
    "tokenized_texts = [tokenizer.encode(prompt_template.format(text), add_special_tokens=True) for text in subset_df['cleaned_text']]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_len = max(map(len, tokenized_texts))\n",
    "padded_texts = [text + [0] * (max_len - len(text)) for text in tokenized_texts]\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_ids = torch.tensor(padded_texts)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    probs = torch.softmax(outputs.logits, dim=1).numpy()\n",
    "\n",
    "# Define label mappings\n",
    "labels_mapping = {\n",
    "    0: 'Question',\n",
    "    1: 'Answer',\n",
    "    2: 'Comment',\n",
    "    3: 'Other'\n",
    "}\n",
    "\n",
    "# Assign labels based on probabilities\n",
    "subset_df['predicted_label'] = [labels_mapping[label] for label in torch.argmax(outputs.logits, dim=1).numpy()]\n",
    "\n",
    "print(subset_df[['cleaned_text', 'predicted_label']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenx_week0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
